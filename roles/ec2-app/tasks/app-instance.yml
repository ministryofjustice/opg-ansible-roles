---

- name: Ensure that appdata is defined
  assert:
    that:
      - appdata is defined
      - instance_name is defined

- name: set data storage fact
  set_fact:
    has_data_storage: "{{ appdata.instance.has_data_storage|default('no') }}"

- block:
    - name: Create security group for app
      ec2_group:
        name: "{{ appdata.server_sg.name }}"
        description: "{{ appdata.server_sg.desc }}"
        rules: "{{ appdata.server_sg.ruleset | rules_from_dict(client_sg_ids.security_groups, appdata.server_sg.client_sg) }}"
        rules_egress: []
        vpc_id: "{{ vpc_id }}"
      register: server_security_group

    - name: Add tags until 2.2
      ec2_tag:
        resource: "{{ server_security_group.group_id }}"
        state: present
        tags: "{{ vpc.env_tags | combine({'Name': appdata.server_sg.name}) }}"

  when: appdata.server_sg is defined

- block:
    - name: Create instance(s) for app component
      ec2:
        instance_profile_name: "{{ appdata.iam_role |default(instance_name + '.' + opg_data.stack) }}"
        instance_type: "{{ appdata.instance.type }}"
        exact_count: 1
        key_name: "{{ vpc.ssh_key_name| default('default') }}"
        group: "{{ appdata.sg }}"
        image: "{{ appdata.ami|default(vpc.ami) }}"
#        wait: yes
        count_tag: "{{ { 'Name': instance_name + '-' + '%02d'|format(item|int) + '.' + opg_data.stack } }}"
        instance_tags: "{{ vpc.env_tags | combine({'Role': instance_name, 'Name': instance_name + '-' + '%02d'|format(item|int) + '.' + opg_data.stack}) }}"
        monitoring: yes
        vpc_subnet_id: "{{ private_subnets[item|int - 1] }}"
        user_data: "{{ lookup('template','bootstrap.j2.sh') }}"
        volumes: "{{ appdata.instance.volumes | default(omit) }}"
      register: app_instance
      with_sequence: count="{{ appdata.instance.count | default(0) }}"

    - name: Add instances to runtime group for later usage
      add_host:
        groups: "{{ appdata.name }}-{{ target }}"
        hostname: "{{ item.private_ip }}"
        ansible_user: "{{ ssh_prov_user|default('jenkins-agent') }}"
        ansible_ssh_common_args: "{{ ssh_conn_opts| default(omit) }}"
        create_time: "{{ item.launch_time }}"
      with_items: "{{ app_instance.results | default([]) | map(attribute='tagged_instances') | list  }}"

    - name: Add instances to ELB
      ec2_elb:
        state: present
        ec2_elbs: [ "{{ instance_name }}-{{ opg_data.stack }}" ]
        instance_id: "{{ item.id }}"
        wait: no
      with_items: "{{ app_instance.results | default([]) | map(attribute='tagged_instances') | list  }}"
      when: has_elb

    - name: Add route 53 records for internal domain
      route53:
        command: create
        overwrite: yes
        record: "{{ item.tags.Name }}.internal."
        zone: "{{ opg_data.stack }}.internal."
        hosted_zone_id: "{{ internal_dns_zone.set.zone_id }}"
        private_zone: yes
        type: A
        value: "{{ item.private_ip }}"
        ttl: 300
      with_items: "{{ app_instance.results | default([]) | map(attribute='tagged_instances') | list }}"


- block:
    - name: Get fact for dns alias
      set_fact:
        cname_source: "{{ app_instance.results | default([]) | map(attribute='tagged_instances') | list }}"

#    - debug:
#        var: cname_source
#    - debug:
#        msg: "{{ cname_source| count }}"
#    - debug:
#        msg:  "{{ cname_source[0][0] }}"

    - name: Add route 53 cname records for internal domain
      route53:
        command: create
        overwrite: yes
        record: "{{ item }}.{{ opg_data.stack }}.internal."
        zone: "{{ opg_data.stack }}.internal."
        hosted_zone_id: "{{ internal_dns_zone.set.zone_id }}"
        private_zone: yes
        type: CNAME
        value: "{{ cname_source[0][0].tags.Name }}.internal."
        ttl: 300
      with_items: "{{ appdata.dns_alias|default([]) }}"

  when: (appdata.instance.count|int == 1) and (appdata.dns_alias is defined)
